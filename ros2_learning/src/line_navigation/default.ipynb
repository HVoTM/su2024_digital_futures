{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](images/openclass_banner_190.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"bg-primary text-center\">\n",
    "    - Summary -\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Line Following** is a foundational skill that underpins many practical applications in robotics. It facilitates efficient navigation, enhances automation, serves as an educational stepping stone, and provides a basis for more advanced robotic functions.\n",
    "\n",
    "In this Open Class, we‚Äôll explore how to implement a line-following robot using **OpenCV** and **ROS2**.\n",
    " \n",
    "\n",
    "What you'll learn:\n",
    "- _Introduction to Line-Following Robots_\n",
    "- _OpenCV computer vision Fundamentals_\n",
    "- _Integration of OpenCV with ROS2 to process images and control robot movement_\n",
    "- _Step-by-step guidance on coding and setting up a line-following robot_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You'll be using the **BOTBOX** throughout the training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BOTBOX is a lab-in-a-box to teach robotics, including off-the-shelf robots, the environment, simulations, and projects for your students.\n",
    "\n",
    "### Your students need to install nothing in order to start programming the robots. Everything is web based and works in any computer.\n",
    "\n",
    "Have full control of your student‚Äôs progress."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](images/IMG_3494.JPG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](images/demosim.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Botbox package includes:\n",
    "\n",
    "![](images/botbox_package.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get more info at https://www.theconstruct.ai/botbox-warehouse-lab/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"bg-primary text-center\">\n",
    "    - End of Summary -\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div>\n",
    "    <h1 class=\"text-center\">\n",
    "        <span class=\"text-primary\">Introduction</span>\n",
    "        &nbsp;\n",
    "        <span class=\"\">What are line following robots? <br><img src=\"https://d2arb8tkr7ck9i.cloudfront.net/wp-content/uploads/2018/01/22145517/1501941_agvs_069_HQ.jpg\"  /></span>\n",
    "            \n",
    "\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Line following** is a fundamental concept in mobile robotics, where a robot is designed to follow a predefined line or path on the ground or surface. This is achieved by using sensors or computer vision that can detect the line or path, typically through contrast or color differences between the line and the surrounding area.\n",
    "\n",
    "Line following is useful for robotics for several reasons:\n",
    "\n",
    "1. **Navigation**: It provides a simple and effective way for robots to navigate through a controlled environment, such as factories, warehouses, or specific areas where a predefined path needs to be followed.\n",
    "\n",
    "2. **Automation**: Line following robots can be used for automated material handling, transportation, or delivery tasks, as they can reliably follow a predetermined route without the need for complex navigation systems.\n",
    "\n",
    "3. **Education and research**: Line following is often used as an introductory project in robotics education and research, as it allows students and researchers to explore fundamental concepts of robot control, sensor integration, and path planning in a simplified and controlled setting.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## So what is this about OpenCV ?\n",
    "\n",
    "OpenCV plays a crucial role in enabling computer vision capabilities for various robotics applications, including line following.\n",
    "\n",
    "OpenCV can be easily integrated into ROS through the `cv_bridge` package, which provides an interface between OpenCV and ROS image messages. This integration allows ROS nodes to subscribe to image topics, process the images using OpenCV functions, and publish the results or control commands back to other ROS nodes.\n",
    "\n",
    "Here's an example of how OpenCV can be used in the context of ROS for line following:\n",
    "\n",
    "1. **Image Acquisition**: A ROS node subscribes to an image topic published by a camera or other image source on the robot.\n",
    "\n",
    "2. **Image Processing**: The received image is converted to an OpenCV format using the `cv_bridge` package. Then, OpenCV functions are applied to the image to detect the line or path. This can involve techniques like color thresholding, edge detection, or contour analysis, depending on the specific line or path characteristics.\n",
    "\n",
    "3. **Line Extraction**: Once the line or path is detected, OpenCV algorithms are used to extract relevant information, such as the line's position, orientation, and curvature.\n",
    "\n",
    "4. **Path Planning and Control**: The extracted line information is then published to other ROS nodes responsible for path planning and motor control. These nodes use the line data to calculate the necessary commands for the robot's actuators (e.g., wheels, motors) to follow the line or path.\n",
    "\n",
    "5. **Visualization and Debugging**: OpenCV can also be used to visualize the processed images and overlay line or path information, which can be useful for debugging and monitoring the line following process.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div>\n",
    "    <h1 class=\"text-center\">\n",
    "        <span class=\"text-primary\">Mission Plan ‚úçÔ∏è</span>\n",
    "        &nbsp;\n",
    "        <span class=\"\">The goal for this openclass üìù</span>\n",
    "    </h1>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have purchased the botbox set from us or you have used the gazebo from the previous Open Class then you may have noticed that the botbox set already comes with line following lines included as part of its set.\n",
    "\n",
    "Your mission for today is to use these tracks to navigate to diffrent areas of the warehouse allowing your boxbot to do it's tasks !\n",
    "\n",
    "![](https://global.discourse-cdn.com/business7/uploads/ros/optimized/3X/b/d/bd8695cf2848499464c53920439bcc8f1e9b683f_2_1380x776.jpeg)\n",
    "\n",
    "![](images/sim.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ready for a challenge? Lets go!¬†"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div>\n",
    "    <h1 class=\"text-center\">\n",
    "        <span class=\"\">Launch the simulation</span>\n",
    "    </h1>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will need to do a small step before launching which is get out April tags into our gazebo environment. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To launch the project simulation:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Open a terminal by clicking:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/rosject_toolbar_terminal.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Run the launch script "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span class=\"badge badge-pill badge-primary\">\n",
    "    <i class=\"fa fa-play\"></i>\n",
    "    &nbsp;\n",
    "    Execute in a Terminal\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ros2 launch tortoisebot_bringup simulation.launch.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Wait around 30 seconds** for simulation to start. It should automatically appear in a Gazebo window.\n",
    "\n",
    "If it doesn't automatically appear, open the Gazebo window by clicking:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/rosject_toolbar_gazebo.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gazebo window should show the Tortoisebot Warehouse world:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/sim.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating our line navigation package"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span class=\"badge badge-pill badge-primary\">\n",
    "    <i class=\"fa fa-play\"></i>\n",
    "    &nbsp;\n",
    "    Execute in a Terminal\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd ~/ros2_ws/src/ \n",
    "ros2 pkg create --build-type ament_python line_navigation --dependencies rclpy std_msgs geometry_msgs sensor_msgs cv2 cv_bridge  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First let's make a simple node that just shows our camera"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](images/add_package.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To find the topic we need to subscribe to run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span class=\"badge badge-pill badge-primary\">\n",
    "    <i class=\"fa fa-play\"></i>\n",
    "    &nbsp;\n",
    "    Execute in a Terminal\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ros2 topic list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user:~/ros2_ws$ ros2 topic list\n",
    "/camera/camera_info\n",
    "/camera/image_raw\n",
    "/camera/image_raw/compressed\n",
    "/camera/image_raw/compressedDepth\n",
    "/camera/image_raw/theora\n",
    "/clock\n",
    "/cmd_vel\n",
    "/joint_states\n",
    "/odom\n",
    "/parameter_events\n",
    "/performance_metrics\n",
    "/robot_description\n",
    "/rosout\n",
    "/scan\n",
    "/tf\n",
    "/tf_static"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can see that `/camera/image_raw` is the topic we want to use. \n",
    "\n",
    "Let's write a script to just first display the feed into an opencv window. \n",
    "\n",
    "You might remember this script from the previous open class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span class=\"badge badge-pill badge-primary\">\n",
    "    <i class=\"fa fa-file\"></i>\n",
    "    &nbsp;\n",
    "    line_navigation.py\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rclpy\n",
    "from rclpy.node import Node\n",
    "from sensor_msgs.msg import Image\n",
    "import cv2\n",
    "from cv_bridge import CvBridge\n",
    "\n",
    "class ImageSubscriber(Node):\n",
    "    def __init__(self):\n",
    "        super().__init__('image_subscriber')\n",
    "        self.subscription = self.create_subscription(\n",
    "            Image,\n",
    "            '/camera/image_raw',\n",
    "            self.listener_callback,\n",
    "            10)\n",
    "        self.subscription  # prevent unused variable warning\n",
    "        self.bridge = CvBridge()\n",
    "\n",
    "    def listener_callback(self, data):\n",
    "        current_frame = self.bridge.imgmsg_to_cv2(data, desired_encoding='bgr8')\n",
    "        cv2.imshow(\"Camera Feed\", current_frame)\n",
    "        cv2.waitKey(1)\n",
    "\n",
    "def main(args=None):\n",
    "    rclpy.init(args=args)\n",
    "    image_subscriber = ImageSubscriber()\n",
    "    rclpy.spin(image_subscriber)\n",
    "    image_subscriber.destroy_node()\n",
    "    rclpy.shutdown()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Edit the setup.py to add the node as a script. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span class=\"badge badge-pill badge-primary\">\n",
    "    <i class=\"fa fa-file\"></i>\n",
    "    &nbsp;\n",
    "    setup.py\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from setuptools import setup\n",
    "\n",
    "package_name = 'line_navigation'\n",
    "\n",
    "setup(\n",
    "    name=package_name,\n",
    "    version='0.0.0',\n",
    "    packages=[package_name],\n",
    "    data_files=[\n",
    "        ('share/ament_index/resource_index/packages',\n",
    "            ['resource/' + package_name]),\n",
    "        ('share/' + package_name, ['package.xml']),\n",
    "    ],\n",
    "    install_requires=['setuptools'],\n",
    "    zip_safe=True,\n",
    "    maintainer='user',\n",
    "    maintainer_email='user@todo.todo',\n",
    "    description='TODO: Package description',\n",
    "    license='TODO: License declaration',\n",
    "    tests_require=['pytest'],\n",
    "    entry_points={\n",
    "        'console_scripts': [\n",
    "            'line_navigation_node = line_navigation.line_navigation:main'\n",
    "        ],\n",
    "    },\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's build and run our new package. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span class=\"badge badge-pill badge-primary\">\n",
    "    <i class=\"fa fa-play\"></i>\n",
    "    &nbsp;\n",
    "    Execute in a Terminal\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd ~/ros2_ws\n",
    "colcon build --packages-select line_navigation\n",
    "source install/setup.bash\n",
    "ros2 run line_navigation line_navigation_node"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In graphical tools you'll see a new opencv window. \n",
    "\n",
    "![](images/graphical_tools.png)\n",
    "![](images/opencv_window.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great, now we can see exactly what the robot's camera will see; the blue line you see is the track that we will want to follow. Let's get to work on making that happen.\n",
    "\n",
    "Now you might already know this if you've ever used computer vision, but there is something about this image that will make it difficult for us to use directly. There is just too much information in the image!!!\n",
    "\n",
    "> But what do you mean by that? More data is better, right???¬†\n",
    "\n",
    "The reality is that most of this image is actually useless to us, and in fact, the only part of the image that we really need is the blue part of the image, which is our line.¬†\n",
    "\n",
    "That brings us to the concept of a **color space**.\n",
    "\n",
    "**Color space** in robotics refers to a method used to represent colors in a way that is easily understandable and computationally efficient for machines. In robotics applications, particularly in tasks like object recognition, tracking, and manipulation, accurately detecting and identifying colors is crucial. There are several color spaces used in robotics, with **RGB** (Red, Green, Blue) and **HSV** (Hue, Saturation, Value) being two common ones.\n",
    "\n",
    "RGB is the most familiar color space, where each color is represented by a combination of red, green, and blue components. While RGB is intuitive and widely used, it's not always the best choice for tasks like color segmentation because variations in lighting conditions can affect the RGB values significantly.\n",
    "\n",
    "**HSV**, on the other hand, represents colors in terms of their hue, saturation, and value.\n",
    "\n",
    "- Hue represents the type of color (e.g., red, blue, or green) and is measured in degrees around a color wheel.\n",
    "\n",
    "- Saturation represents the intensity or purity of the color and is typically expressed as a percentage.\n",
    "\n",
    "- The value represents the brightness of the color.\n",
    "\n",
    "![](https://lindevs.com/uploads/posts/content/2021/07/convert_image_from_rgb_to_hsv_color_space_using_opencv.png?v=1680423474)\n",
    "\n",
    "**HSV** is often preferred in robotics because it *separates the color information* from the brightness information, making it more robust to changes in lighting conditions. This makes it easier to segment objects based on their color, regardless of variations in lighting.\n",
    "\n",
    "Once we convert the image to this HSV color space we need to isolate the blue color in the image, for this we will use whats called a **binary mask**. You might be familiar with the concept of masking if you've ever used the software Photoshop.\n",
    "\n",
    "In OpenCV, a **binary mask** is a type of image where each pixel is either black (0) or white (255), typically representing foreground and background regions. It's used for tasks like image segmentation, where you want to isolate certain regions of interest in an image. For instance, in object detection, a binary mask can be created to highlight the pixels corresponding to the detected object while suppressing the rest of the image. **This makes it easier to extract and work with specific objects or regions in an image.**\n",
    "\n",
    "So lets go through our plan again.¬†\n",
    "\n",
    "1. Convert the image from the BGR color space to the HSV color space.\n",
    "2. Define a range of HSV values that correspond to the blue color.\n",
    "3. Create a binary mask where pixels within the specified HSV range are set to white (255) and all other pixels are set to black (0)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's modify the code accordingly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rclpy\n",
    "from rclpy.node import Node\n",
    "from sensor_msgs.msg import Image\n",
    "from cv_bridge import CvBridge\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "class ImageSubscriber(Node):\n",
    "    def __init__(self):\n",
    "        super().__init__('image_subscriber')\n",
    "        self.subscription = self.create_subscription(\n",
    "            Image,\n",
    "            '/camera/image_raw',\n",
    "            self.listener_callback,\n",
    "            10)\n",
    "        self.subscription  # prevent unused variable warning\n",
    "        self.bridge = CvBridge()\n",
    "\n",
    "    def listener_callback(self, data):\n",
    "        # Convert ROS Image message to OpenCV image\n",
    "        current_frame = self.bridge.imgmsg_to_cv2(data, desired_encoding='bgr8')\n",
    "        \n",
    "        # Convert BGR to HSV\n",
    "        hsv_image = cv2.cvtColor(current_frame, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "        # Define range of blue color in HSV\n",
    "        lower_blue = np.array([100, 50, 50])   # Lower bound of blue color\n",
    "        upper_blue = np.array([130, 255, 255])  # Upper bound of blue color\n",
    "\n",
    "        # Create a binary mask\n",
    "        blue_mask = cv2.inRange(hsv_image, lower_blue, upper_blue)\n",
    "\n",
    "        # Apply the mask to the original image\n",
    "        blue_segmented_image = cv2.bitwise_and(current_frame, current_frame, mask=blue_mask)\n",
    "\n",
    "        # Display the segmented image\n",
    "        cv2.imshow(\"Blue Segmented Image\", blue_segmented_image)\n",
    "        cv2.waitKey(1)\n",
    "\n",
    "def main(args=None):\n",
    "    rclpy.init(args=args)\n",
    "    image_subscriber = ImageSubscriber()\n",
    "    rclpy.spin(image_subscriber)\n",
    "    image_subscriber.destroy_node()\n",
    "    rclpy.shutdown()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's rebuild and run our new package. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span class=\"badge badge-pill badge-primary\">\n",
    "    <i class=\"fa fa-play\"></i>\n",
    "    &nbsp;\n",
    "    Execute in a Terminal\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd ~/ros2_ws\n",
    "colcon build --packages-select line_navigation\n",
    "source install/setup.bash\n",
    "ros2 run line_navigation line_navigation_node"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/step_1_line.png\" style=\"width: 300px\" />\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2 \n",
    "\n",
    "Bravo !!!\n",
    "\n",
    "Well we have line ...\n",
    "\n",
    "Now what ...\n",
    "\n",
    "Well now we need to detect the line as a line !\n",
    "\n",
    "What does this mean ? We can see the blue line and so can the robot but right now the robot does not understand where is the line, all it knows is where all the blue is in the image.\n",
    "\n",
    "For this we will need to use something called Contour detection.\n",
    "\n",
    "![](https://dontrepeatyourself.org/static/img/edge-and-contour-detection/contour-detection-after-dilation-on-coins.webp)\n",
    "\n",
    "Contours in image processing are **curves joining continuous points having the same color or intensity**. They are a fundamental concept used for shape analysis and object detection in computer vision. In OpenCV, **contours are represented as a list of points**.\n",
    "\n",
    "In the context of line detection for robotics, contours are used to approximate the shape of objects or features in an image. Here's how contours are typically used in this case:\n",
    "\n",
    "- **Detection of Features**: Contours help in identifying regions or features of interest in an image. For example, in line-following applications, contours can help detect the boundaries of the line on the ground.\n",
    "\n",
    "- **Segmentation**: Once contours are detected, they can be used to segment the image, isolating the regions corresponding to the detected features. In this case, contours help in segmenting the image to focus only on the line.\n",
    "\n",
    "- **Shape Analysis**: Contours provide information about the shape of objects. For instance, in line detection, contours can give an approximation of the shape of the line, allowing for further analysis such as calculating the slope of the line.\n",
    "\n",
    "Once we have the Contours in the mask we then need to calculate what is called the **Centroid**. \n",
    "\n",
    "The **Centroid** in this case is the geometric center of our **detected Contour**. \n",
    "\n",
    "For this we will be using the `cv2.moments()` function of OpenCV.\n",
    "\n",
    "So now to process each contour we need to:\n",
    "\n",
    "1. Find the Contours in the mask\n",
    "\n",
    "The `cv2.findContours()` function can be used to identify contours in the binary image mask. It returns a list of contours and a hierarchy.\n",
    "\n",
    "2. Iterate over detected Contours and compute its moments\n",
    "\n",
    "For each contour found, compute its moments using `cv2.moments()`.\n",
    "\n",
    "The moments M include quantities like area, centroid, etc., which are used to compute properties of the contour.\n",
    "\n",
    "If the area of the contour (M['m00']) is greater than `MIN_AREA_TRACK`, it is considered significant.\n",
    "\n",
    "3. Extract Centroid\n",
    "\n",
    "If a contour satisfies the area conditions, its centroid coordinates (`x` and `y`) are calculated.\n",
    "\n",
    "line['x'] is set to the x-coordinate of the centroid adjusted by crop_w_start.\n",
    "line['y'] is set to the y-coordinate of the centroid.\n",
    "\n",
    "4. Display the processed image\n",
    "\n",
    "Now that we know this let's edit the code.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def get_contour_data(self, mask):\n",
    "        \"\"\"\n",
    "        Return the centroid of the largest contour in the binary image 'mask' (the line) \n",
    "        \"\"\" \n",
    "        # Constants\n",
    "        MIN_AREA_TRACK = 50  # Minimum area for track marks\n",
    "\n",
    "        # get a list of contours\n",
    "        contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
    "\n",
    "        line = {}\n",
    "\n",
    "        for contour in contours:\n",
    "            M = cv2.moments(contour)\n",
    "\n",
    "            if (M['m00'] > MIN_AREA_TRACK):\n",
    "                # Contour is part of the track\n",
    "                line['x'] = int(M[\"m10\"]/M[\"m00\"])\n",
    "                line['y'] = int(M[\"m01\"]/M[\"m00\"])\n",
    "\n",
    "        return (line)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will make a new function called get_contour_data which will take our mask as an input and output the line as an output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "        # Detect line and get its centroid\n",
    "        line = self.get_contour_data(blue_mask)\n",
    "\n",
    "        # Display the segmented image with line centroid\n",
    "        if line:\n",
    "            cv2.circle(blue_segmented_image, (line['x'], line['y']), 5, (0, 0, 255), 7)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then add it to our `listener_callback` so that it runs every frame we get from the camera."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's rebuild and run our package. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span class=\"badge badge-pill badge-primary\">\n",
    "    <i class=\"fa fa-play\"></i>\n",
    "    &nbsp;\n",
    "    Execute in a Terminal\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd ~/ros2_ws\n",
    "colcon build --packages-select line_navigation\n",
    "source install/setup.bash\n",
    "ros2 run line_navigation line_navigation_node"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](images/step_2_result_line.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Take off üöÄ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great job so far !\n",
    "\n",
    "So far we've isolated our line, detected the contour and calculated our centroid.\n",
    "\n",
    "Now all that's left is the 'following' part of the line following algorithm.\n",
    "\n",
    "There are many methods of implementing this part such as PID or model predictive control but thats a little too complicated for this lesson so we will be implmenting a simple proportional control based on the calculated displacement (error) from the centerpoint of the input image multiplied by a proportional constant.¬†\n",
    "\n",
    "For this we will travel forward at a constant linear velocity ¬†`x` and only change the angular turning velocity `z`.¬†\n",
    "\n",
    "To calculate error we will use:¬†\n",
    "\n",
    "```\n",
    "\n",
    "error = x - width//2\n",
    "```\n",
    "\n",
    "This is the¬† `line['x']` of the line minus the half the width of the image, basically the deviation from the center point.¬†¬†\n",
    "\n",
    "For calculating the final angular velocity:¬†\n",
    "\n",
    "```\n",
    "cmd.angular.z = float(error) * -KP\n",
    "```\n",
    "\n",
    "Here we take our calculated error and multiply it with a proportional constant. You can finetune the constant to depending on how well the robot turns.¬†\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add the two constants to the top of the script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear forward speed\n",
    "LINEAR_SPEED = 0.2\n",
    "\n",
    "# Proportional constant to be applied on speed when turning \n",
    "# (Multiplied by the error value)\n",
    "KP = 1.5/100 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a new publisher to publish Twist commands to the /cmd_vel topic. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "        self.publisher = self.create_publisher(Twist, '/cmd_vel', 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modify the callback code to implement the new calculation and send the command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "        # Move depending on detection \n",
    "        cmd = Twist()\n",
    "        _, width, _ = blue_segmented_image.shape\n",
    "        if line:\n",
    "            x = line['x']\n",
    "\n",
    "            error = x - width//2\n",
    "\n",
    "            cmd.linear.x = LINEAR_SPEED\n",
    "            cv2.circle(blue_segmented_image, (line['x'], line['y']), 5, (0, 0, 255), 7)\n",
    "        \n",
    "        # Determine the speed to turn and get the line in the center of the camera.\n",
    "        cmd.angular.z = float(error) * -KP\n",
    "        print(\"Error: {} | Angular Z: {}, \".format(error, cmd.angular.z))\n",
    "\n",
    "        # Send the command to execute\n",
    "        self.publisher.publish(cmd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's rebuild and run our package. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span class=\"badge badge-pill badge-primary\">\n",
    "    <i class=\"fa fa-play\"></i>\n",
    "    &nbsp;\n",
    "    Execute in a Terminal\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd ~/ros2_ws\n",
    "colcon build --packages-select line_navigation\n",
    "source install/setup.bash\n",
    "ros2 run line_navigation line_navigation_node"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](images/fail_1.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Challenge üö®"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's working!!! ... until it doesn't.¬†\n",
    "\n",
    "The issue seems to be that it detects a line that is very far away and goes to that one instead, which causes it to run into the wall.¬†\n",
    "\n",
    "There are actually many ways to fix this issue, like cropping the input frame, for instance. However,¬† there is already a way to fix this in the code itself. Can you figure it out?¬†"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you do you should get something like this:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](images/pass_1.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While so far we've been able to follow the line to the end, when it does reach the end, it's at a crossroads of where to go.¬†\n",
    "\n",
    "Modify the `get_contour_data` to also detect such situations and edit the `listener_callback` to decide which line to change to and try to replicate the same mission of getting to the dispatch station with just the line following.¬†\n",
    "\n",
    "When you have completed it, take a screen recording and tag us on X (twitter) or facebook.¬†\n",
    "\n",
    "![](images/final_step.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Share your work üì®"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We love seeing what our students do with the things they learn here so please do share what you do on social media and make sure to tag us so we know."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Twitter (X) | @_TheConstruct_](https://twitter.com/_theconstruct_) ![](data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAMwAAADACAMAAAB/Pny7AAAAaVBMVEUdm/D///8Ale8Ak+8UmfAAl+8Ake75/P4AkO/0+f4Aju4AjO7w9/7P5fvW6fvo8v2ay/fg7vyz1vip0fjJ4fpEpvG82/mTxvY9o/GKwvVTq/JarvKCv/UrnvByuPR7u/Rns/MAh+6GufT6RDBTAAAKJUlEQVR4nN2d14KrvA5GwcgGEnrv8J/3f8gDyWQPxRCaKPPdzSQhrBjbsixLgviHJJx9A7+SZdn0Aseq5Qa6rdZ/L7zCNWBkTdOtSng+H4xJtRhTnk9IQ0/TlgBdAEY2DTdhikSEnihRHr6lm+rcK50Oo9UkCqPQJ/kASUpkGea8a50MY3oZKKMkbwEjRWDPudqpMGZQsMHDxcOhJHVm4JwIowaZQqYbpYXDKkf7dsXzYIxQmNMqvzg086avKJ8FozrJEpSXpMiaaBw1iGsY2zmO4SM7zulSlrp1SKGPXFBzy4gIolxFY+9Ak5fCzM7SE/G5v7wRVnkzJoq6QquZ4/heCqIvo/G4aG71bQLTLXzhfUExoUDLrwPFjpJdYcUj9hFA3L5Zzan8nH5+G/vRjBThUptuA4s1dzweEck+NLabRPXN/75UNoMKUPc4FmkTSjMMNDRaUOR1x+v+Lu9LAz1qSHOVbe3SiKQVkObZ6l+KfnC/zEg7KfhvM0pz018Gw2NojF1YxhBbNBR/ulGfiCwd64ii08hrpv3ZkoIOGTZNvNgcWyASip2/KUGl8bYOyhOqJ35R7P8LcRTQIlQWuQ8jgBSgwcQrjctZLFnj9Rj+20WybIwcjYX+2GscyKkV0HrJJR5L/nPLw5eAxrNcIQsVRFgw9Rrnx7PGJS2M3VnkEmuKIZX+7hiywXsZaLL7oOb5ODAULPMF4mRVwn0H0GhvIzpGaphKt3UnrpJ6hUbGvoJCONvDO0dGigQTJX6UA6WTdjTs6xhw0YwyGKzQuDTCfsOAlmFaZXMED2svGN1Hm2RmS/F36jjuRh/GLqLPXUw1FdX2n69nsUPj2BXmomyBJAg222oeno25UFQq7I2GtMOOudMZ7wGSu5vmnO1+v1ki/qy3Aam2PGtmeUT/JwnX0OSIQuatftaO6P/AKpu7BOC+WYrCtRaBgWQxt2+PlCZ/PcMXlZKVOPp342mjAMKmGyz5CKVpuGYk8LC7DInejouFn1qF4+GOzCAlP/156SepkCx2EXgKBsNHQMvPDS3/MAW/XNZ3AlQYWv4zuFb0zXo1lFdLDFBcGBL/+6J1e6X18i6yZluguI9ZG2Zl5wSBsmqmmx0ZJvuFidZPaFRh8ZyxDXc0a8Ns+tlAegrW18FNR50z2zAi3WhrsEdt6KhThpuB5plt1IHZvtigkiKUga2NjQh2gmmbdWD22WgkSm26eYbJi3Y1i8NgxGCn/kmJwvzY1Q27R6SGqHuZcRtGrfb7LkqYIqSZFXh6q5VQl81dGNHY10QHSiSFREkRW45TU+k2nnNWGMCgrNFrJCIxRnLfTxPMBQ0NOzCiWeF5HGrLh64OlZujPozooc4EqALB6sHILt62NrZytwfTeINvSgO504cRteIQR93+gigYwIhmek8a6utDmNqCusa+w0LRxObAiCa+rw5BNDV5MKIW3bBtSPFrCAqkHQSc3G9Ma+LM/sEIilJ4/87d3W+Eplkb5rWWrxxb05rlYpCffXfL1DYAfpyAQNlDSGPHs03jXjTtObPt0WzWIg8F7mWmQWua4QTP3YqlnmbMCZibiabyH4IpxD8DA0L4d2CEPPg7MBDZfweG+uLfgRGqvwPTMWbuDiPknZhl9HgDVEHe2XnYcv7zfHX7v7joGPvlRMMujHtPp8xb0A3zF0TUrWBcAYg9mGPC9FAESR9Gve+ARtw+zFHhoAhi5gBGxTpBgS9xACPqN1sqf9TaAPyFka17TjbPfmzIq6W04pY0ROTBiIZ/Q5pWNEMHRnZQz4PjaPCUfXYBZAt1RxhDAIPIls/opsZ3o5HCPsvv/oxa3mwD4DmM2/udd+R7DWk0GUaEtSfR6k5to3COxXYsglK6DQ0QTnRo17yxbkNDYk7cYc9W8+4Co/CC3vuGp5zAHaZPwj2sPEyjZ+U3mHEY91Q8JyegXazPpXaQwOcGU3MTHAZVfu1RWhqknxuHEVWnbp3r9h2a808hjKWeVIM4IVdtHjKSeWE8j6asu5kvSRfsPpCPpPiYTAqq6U5YXOAof0+/SQGnYDi9ynD5OUNOFORjx6o6MNr/YjfQDdvUNNM2PMcqq9S/XPgJGU2U2X3MIppHvp+85Ee5QAlcrs90omWmYFz6iql+CeCa7rR2tNwkjHz99Vk7WnYaRkTLqLSbSMEH4cCYj7Nv9otgKoVxf55BPVG1g2CiYQYwGmqmy82CaOos5cACuHYYPQydZVMw6pVhwOcxjMOI7nU30oBOnw8fwsjX3REgFYdgEua6G2kAX/LFcGAuu5HGc2J+gxG1Q5LeLBZJv7DwF2d2ekUa+jXZBX+l6V3w8MnXh2wM5oLbgtKMRGsjPgDZvRgN5DMyqow5NLaVVdhdwOakUxn1zlyLRpmVo3TC1RRcZz+ApJtrNhlwkTENhHmJfSedgLJ/DROazEzr+6XMUcgu8KhJc2uwfKvZZOenm538XbI1MM1O2rlxj51TZVthRLPMT/RrjnuWV8HUK5zSP2uYBmFBmZ+Zdc70MM1xU2GMsNBJD8Y6mKZmVZkI5GgekiHV05QNt9l6YuTtVT+EpViUWHVhOT3Tc624SP0oP2LbRkqXpYZcURtQMw3d8zL8tMWEv9u/K0wj2cHfHST+0oSq62DMDH/tRqLFyWFXwXgJfv9f3i6rYOTwAHttRbusgTGiA4ZlKVmTgHgxTEkOsDvZKpalMN7sEribWOatkrfBmP4OVQpnsCyb91fBaJlyhOn8UxkLE0Y2w2ExchQWYYmdvAZGta21GXcXiuYbypTOgdH0UGCHWMlA/C2VSL7CyLZX0oO2OYFUm6qSfYExdTc9pNs3ohBvK9oxBaPpTpkfhlJbY1ur+o7C1MuwzJeOCzml46W/t8G8YzPJaOEwBJF8h5KEA5i6l8RFkh/rugCWBjsUi2ydbDKNwMrKym9AjnXCEAh3qa0o6F7guFZcVmniR0L9aB3v7WNJsE/VLiGKGk/LK9vtOT5YQlZVG+HCnBxXSllq7FZa9USORhJxdqwSeyoK+a9/CP62MPTJOWq5DeaknRcAaam/cgZMdMbOSz3o7F8Ztpk0g+TobUuAPEWpdd1YAEEVHReNUc9mUYFUhPxtzuiZf8yUCURIMrTq8B/bzLaqCNtKBkqi6nuFl+0wtd0fxCkQvO5D60aJdzLCvsKIzZmsLJFQeCiBJHP3L9Q9ASOKqu6W9fpy3+eNEuJnro7aKDwY8bXMjBPKdhoPgDCaxI6OUtn+O0zDY3huIbCtZzSBkEdeuJ5xCMkYjPhed4YVPNY+cnWLPPLK0g1zR6t4LUwj1TR0t/AVhS0iIjUHrbu7bpv43aSjbx5NWTNtz81SeDyYJE25OWjdz5nyVKIqdAyTW7wJW7Mc57KqaS93Rz2xPp7Ph8IYk2q2lxhTHvU/pTwpQtczm7zvJ3C8tGSzSW6kqrbhNU4Q17VquW5TycjWXq+dBfHRyqCGa+r/SKyTaDwx1F4AAAAASUVORK5CYII=)\n",
    "\n",
    "[Facebook | The Construct ](https://www.facebook.com/theconstructsim) ![](data:image/png;base64,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)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
